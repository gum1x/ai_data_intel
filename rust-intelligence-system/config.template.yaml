# Intelligence System Configuration Template
# Copy this file to config.yaml and fill in your actual values

system:
  name: "AI Intelligence System"
  version: "1.0.0"
  environment: "development"  # development, staging, production
  debug: true
  log_level: "INFO"

server:
  host: "0.0.0.0"
  port: 8080
  workers: 4
  max_connections: 1000
  timeout_seconds: 30
  enable_cors: true
  cors_origins: ["*"]

database:
  postgres_url: "postgresql://intelligence:password@localhost:5432/intelligence"
  max_connections: 20
  min_connections: 5
  connection_timeout_seconds: 30
  idle_timeout_seconds: 600
  max_lifetime_seconds: 1800

redis:
  url: "redis://localhost:6379"
  max_connections: 10
  connection_timeout_seconds: 5
  command_timeout_seconds: 3

kafka:
  bootstrap_servers: ["localhost:9092"]
  group_id: "intelligence-system"
  auto_offset_reset: "latest"
  enable_auto_commit: true
  session_timeout_ms: 30000
  heartbeat_interval_ms: 3000
  max_poll_interval_ms: 300000

security:
  jwt_secret: "your-super-secret-jwt-key-here-must-be-32-chars-min"
  jwt_expiry_hours: 24
  encryption_key: "your-super-secret-encryption-key-32-chars"
  rate_limit_requests: 1000
  rate_limit_window_seconds: 3600
  allowed_ips: []
  enable_audit_logging: true
  password_min_length: 12
  password_require_special_chars: true

monitoring:
  prometheus_port: 9090
  jaeger_endpoint: "http://localhost:14268/api/traces"
  log_level: "info"
  enable_tracing: true
  metrics_retention_days: 30

ai_providers:
  openai:
    api_key: "your-openai-api-key-here"
    model: "gpt-4"
    max_tokens: 4000
    temperature: 0.7
    rate_limit: 60
  
  anthropic:
    api_key: "your-anthropic-api-key-here"
    model: "claude-3-sonnet-20240229"
    max_tokens: 4000
    temperature: 0.7
    rate_limit: 60
  
  google:
    api_key: "your-google-api-key-here"
    model: "gemini-pro"
    max_tokens: 4000
    temperature: 0.7
    rate_limit: 60
  
  huggingface:
    api_key: "your-huggingface-api-key-here"
    model: "microsoft/DialoGPT-medium"
    max_tokens: 1000
    temperature: 0.7
    rate_limit: 60
  
  cohere:
    api_key: "your-cohere-api-key-here"
    model: "command"
    max_tokens: 4000
    temperature: 0.7
    rate_limit: 60
  
  together:
    api_key: "your-together-api-key-here"
    model: "meta-llama/Llama-2-7b-chat-hf"
    max_tokens: 4000
    temperature: 0.7
    rate_limit: 60

telegram:
  bot_token: "your-telegram-bot-token-here"
  api_id: 12345
  api_hash: "your-telegram-api-hash-here"
  phone_number: "+1234567890"
  max_concurrent_sessions: 5
  rate_limit_per_second: 30
  batch_size: 1000
  collection_timeout_seconds: 300

agents:
  max_concurrent_agents: 10
  agent_timeout_seconds: 300
  communication_timeout_seconds: 30
  retry_attempts: 3
  retry_delay_seconds: 5

analytics:
  batch_size: 1000
  processing_interval_seconds: 60
  enable_real_time: true
  max_memory_usage_mb: 8192
  cpu_limit_percent: 80.0
  enable_parallel_processing: true
  enable_distributed_processing: true
  chunk_size: 1000
  max_retries: 3
  retry_delay_seconds: 5
